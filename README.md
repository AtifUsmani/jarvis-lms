# This is Highly Experimental. It might not work on your computer

# Project Configuration Guide

This project was built with **LM Studio** and the **qwen2.5-7b-instruct** LLM in mind.
It now uses **Mem0** for long-term memory and integrates with:
- A local/remote **LLM (Large Language Model)**
- **Home Assistant** for smart home control
- **TTS (Text-to-Speech)** via GPT-SoVITS
- A custom **Spider-Bot**

---

## âš™ï¸ Configuration

All settings are stored in [`example.yaml`](./example.yaml).  
Copy it to `config.yaml` and update the values to match your environment:

```bash
cp example.yaml config.yaml
````

### Sections in `config.yaml`

* **LLM** â†’ Model name, API base URL, and API key (if needed).
* **HA** â†’ Home Assistant URL and token.
* **HA\_TOOLS** â†’ Entity IDs (light, sensors, etc.).
* **TTS** â†’ Text-to-Speech API endpoint and test sentence.
* **SPIDER-BOT** â†’ Bot MAC address and network subnet.

> âš ï¸ **Important:** Update the absolute path of your `config.yaml` inside `memory/memory.py`.

---

## ğŸ”‘ Generating a Home Assistant Token

1. Log in to Home Assistant.
2. Go to **Profile â†’ Long-Lived Access Tokens**.
3. Generate a new token and copy it into `HASS_TOKEN` inside `config.yaml`.

---

## ğŸ“¦ Installation (with `uv`)

1. Install dependencies:

   ```bash
   uv sync
   ```

2. Run your project:

   ```bash
   uv run python main.py
   ```

---

## ğŸ™ï¸ STT, TTS & Wake Word Options

Inside `main.py`, you can enable or disable features by setting the following flags:

```python
USE_STT = True       # Speech-to-Text
USE_TTS = True       # Text-to-Speech
USE_WAKEWORD = True  # Wake word detection
```

This gives you full control over which components are active.

---

## ğŸ—£ï¸ Text-to-Speech (TTS)

The project uses **GPT-SoVITS** for Text-to-Speech.
You need to **set up and start the TTS service manually** before running the project.

---

## ğŸ™Œ Credits

This project stands on the shoulders of amazing open-source tools and research:

* **[**LM Studio**](https://lmstudio.ai/)** â€“ LLM hosting and API interface
* **[**Qwen2.5-7B-Instruct**](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct)** â€“ Language model backend
* **[**Mem0**](https://github.com/mem0ai/mem0)** â€“ Long-term memory system
* **[**Home Assistant**](https://www.home-assistant.io/)** â€“ Smart home integration
* **[**GPT-SoVITS**](https://github.com/RVC-Boss/GPT-SoVITS)** â€“ Text-to-Speech engine
* **[**Vosk**](https://alphacephei.com/vosk/)** â€“ Speech recognition / wake word detection
